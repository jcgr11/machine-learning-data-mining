---
output:
  pdf_document: default
  html_document: default 
---

---
title:  'Home Equity Loan Customer Pre-screen and Scoring'
author:
- Julio Rengifo
date: "`r format(Sys.time(), '%d %B %Y')`"
output: pdf_document
---

```{r message=FALSE, warning=FALSE}
# install.packages("Rcpp")
install.packages("tinytex")
```

# Problem

The aim of this Project is to, through decision tree model and logistic regression model, complete two common practices in credit risk management which are *customer pre-screening* and *customer scoring*. The two tasks are expected to provide value information to support decision makings at the levels of operative management and middle management.

# Data
```{r message=FALSE, warning=FALSE}
# import data
install.packages("readr")
library(readr)
hmeq <- read_csv("hmeq.csv")
head(hmeq)
```

```{r message=FALSE, warning=FALSE}
# import data
install.packages("dplyr")
library(dplyr)
hmeq_rev <- hmeq%>% select(-JOB)
head(hmeq_rev)
```

**From a regulatory standpoint the final decision the is made must be as unbiased as possible. When using a model like this its very likely that including data such as job title may distort the model results in a way that unintentionally discriminates toward specific job titles because it may be seeing patterns/relationships between the individual being a "bad" borrower that are not true and even if true in some cases can present very harmful regulatory issues that can hurt the bank's reputation, credibility, and can result in costly litigation expenses if it is very serious.**

```{r message=FALSE, warning=FALSE}
install.packages(c("caret", "mlbench"))
library(caret)
library(mlbench)
set.seed(2020)
inTrain <- createDataPartition(y = hmeq_rev$BAD,# the target attribute is used as the stratifying factor
                               p = 0.70, # The percentage of data records labled as the training data
                               list=FALSE)

training <- hmeq_rev[as.vector(inTrain),] # select all records labeled as training data and create the test set
test <- hmeq_rev[-as.vector(inTrain),] # use the rest data to create the training set

nrow(training)
table(training$BAD)/nrow(training)
nrow(test)
table(test$BAD)/nrow(test)
```

# Analysis

## Decision tree model (customer pre-screening)

```{r message=FALSE, warning=FALSE}
install.packages("rpart")
install.packages("rpart.plot")
library(rpart.plot)
library(rpart)

# preprocess data
hmeq_rev_df <- data.frame(hmeq_rev)
hmeq_cols <- colnames(hmeq_rev_df)[-which(colnames(hmeq_rev_df) %in% c("BAD", "BAD_Label"))]

# set up DT formula string
DT_formula_str <- paste0("BAD_Label ~ ",
                         paste(hmeq_cols,
                               collapse = "+"))

print(DT_formula_str)

# Underfit
hmeq_underfit <- rpart(DT_formula_str,
                       data = training,
                       parms = list(split = 'gini'),
                       control = rpart.control(minisplit = 3000))

rpart.plot(hmeq_underfit)

# Displaying misclassification for underfit model
training.predict.underfitting <- predict(hmeq_underfit,
                                         newdata = training,
                                         type = "class")
table(training.predict.underfitting,
      training$BAD_Label)

# Overfit
hmeq_overfit <- rpart(DT_formula_str,
                      data = training,
                      parms=list(split='gini'),
                      control=rpart.control(cp=0))

rpart.plot(hmeq_overfit)

# Displaying misclassification for underfit model
training.predict.overfitting <- predict(hmeq_overfit,
                                        newdata = training,
                                        type = "class")
table(training.predict.overfitting,
      training$BAD_Label)

# Pruning the decision tree
hmeq_rpart_pruned <- rpart(DT_formula_str, data = training,
                           parms=list(split='gini'),
                           control=rpart.control(cp=0))
printcp(hmeq_rpart_pruned)

# Choose the best tree model based on the cp value with the smallest xerror
hmeq_rpart_best <- rpart(DT_formula_str,
                         data = training,
                         parms=list(split='gini'),
                         control=rpart.control(cp= 0.0151515))
rpart.plot(hmeq_rpart_best)

```

```{r message=FALSE, warning=FALSE}
imp <- as.data.frame(varImp(hmeq_rpart_best, scale = TRUE))
imp <- data.frame(names = rownames(imp), overall = imp$Overall)
imp[order(imp$overall,
          decreasing = T),]
```

**Based on the importance scores the top 5 values important predictors for predicting BAD are DEBTINC, DELINQ, DEROG, CLAGE, VALUE.**

## Logistic regression model (customer scoring)

```{r message=FALSE, warning=FALSE}
install.packages("car")
library(car)

# set up lgr formula using the top 5 attributes from decision tree model
hmeq_lgr <- glm(BAD~DEBTINC+DELINQ+DEROG+CLAGE+VALUE,
                data = hmeq_rev,
                family = binomial(link = logit))
hmeq_lgr
# address the concern of multicollinearity 
vif(hmeq_lgr) #the vif() output indicates that there is no significant multicollinearity.

# display the importance of different factors
varImp(hmeq_lgr, scale = TRUE)

```

**Based on my final model result it is apparent that DELINQ is the the most significant predictor of BAD (all else equal), with every one-unit increase in in DELINQ the log probability of BAD increases by .6632)**

```{r message=FALSE, warning=FALSE}
confint(hmeq_lgr, "DELINQ", level = 0.95)
```

**Based on this model and the assumption of causality relationship between BAD and other predictors in the logit regression, we predict with 95% confidence that for every one unit increase in DELINQ the odds of a BAD outcome will increase by a possible value in the range between 54% to 79%.**

```{r message=FALSE, warning=FALSE}
install.packages("DescTools")
library(DescTools)
Cstat(hmeq_lgr)
```

**The Cstat measure suggests that my model performance is good.**
